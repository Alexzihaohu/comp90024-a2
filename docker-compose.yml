version: "3.8"
services:
  visualizer:
    image: dockersamples/visualizer:stable
    ports:
      - "8001:8080"
    stop_grace_period: 1m30s
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    deploy:
      update_config:
        failure_action: rollback
      placement:
        constraints:
          - 'node.role == manager'
    networks: 
      - backend

  portainer:
    image: portainer/portainer
    ports:
      - "9000:9000"
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    deploy:
      replicas: 1
      placement:
        constraints: [node.role == manager]
    networks: 
      - backend

  couchdb:
    image: "ibmcom/couchdb3:3.0.0"
    ports:
      - "5984:5984"
      - "4369:4369"
      - "9100:9200"
    volumes:
      - ./opt/couchdb/data:/opt/couchdb/data
    environment:
      - COUCHDB_USER=user
      - COUCHDB_PASSWORD=pass
      - NODENAME={{.Task.Name}}
    configs:
      - source: couchdb_conf
        target: /opt/couchdb/etc/local.d/config.in
    networks:
      - backend
    command: /bin/bash -c "cp -f /couchdb_conf /opt/couchdb/etc/local.d/couch.ini"
    deploy:
      mode: replicated
      replicas: 3
      placement:
          constraints: [node.role == manager]
        
  twitterlance:
    image: "yangzy3/twitterlance"
    container_name: twitterlance-app
    ports:
      - "80:80"
    links:
        - couch_master
        - couch_slave1
        - couch_slave2
    environment:
        - NODENAME={{.Task.Name}}
    command: python /code/manage.py initcouchdb
    networks:
      - backend
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints: [node.role == worker]
        
networks:
  backend:
    driver: overlay
    ipam:
      config:
        - subnet: 172.20.0.0/16.

configs:
  couchdb_conf:
    file: ./couchdb.ini