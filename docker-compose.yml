version: "3.8"
services:
  visualizer:
    image: dockersamples/visualizer:stable
    ports:
      - "8001:8080"
    stop_grace_period: 1m30s
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    deploy:
      update_config:
        failure_action: rollback
      placement:
        constraints:
          - 'node.role == manager'

  portainer:
    image: portainer/portainer
    ports:
      - "9000:9000"
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    deploy:
      replicas: 1
      placement:
        constraints: [node.role == manager]

  couch-master:
    image: "ibmcom/couchdb3:3.0.0"
    restart_policy:
      condition: on-failure
      delay: 5s
    ports:
      - "5984:5984"
      - "4369:4369"
    links:
      - couch_slave1
      - couch_slave2
    volumes:
      - ./data/master/data:/opt/couchdb/data
    environment:
      - COUCHDB_USER=user
      - COUCHDB_PASSWORD=pass
      - NODENAME=172.20.0.2
    container_name: couch_master
    networks:
      backend:
        ipv4_address: 172.20.0.2
    deploy:
      mode: replicated
      replicas: 1
      placement:
          constraints: [node.role == manager]

  couch_slave1:
    image: "ibmcom/couchdb3:3.0.0"
    restart_policy:
      condition: on-failure
      delay: 5s
    ports:
      - "15984:5984"
    volumes:
      - ./data/slave1/data:/opt/couchdb/data
    environment:
      - COUCHDB_USER=user
      - COUCHDB_PASSWORD=pass
      - NODENAME=172.20.0.3
    container_name: couch_slave1
    networks:
      backend:
        ipv4_address: 172.20.0.3
    deploy:
      mode: replicated
      replicas: 1
      placement:
          constraints: [node.role == worker]

  couch_slave2:
    image: "ibmcom/couchdb3:3.0.0"
    restart_policy:
      condition: on-failure
      delay: 5s
    ports:
      - "25984:5984"
    volumes:
      - ./data/slave2/data:/opt/couchdb/data
    environment:
      - COUCHDB_USER=user
      - COUCHDB_PASSWORD=pass
      - NODENAME=172.20.0.4
    container_name: couch_slave2
    networks:
      backend:
        ipv4_address: 172.20.0.4
    deploy:
      mode: replicated
      replicas: 1
      placement:
          constraints: [node.role == worker]
        
  twitterlance:
    image: "yangzy3/twitterlance"
    container_name: twitterlance-app
    ports:
      - "80:80"
    links:
        - couch_master
        - couch_slave1
        - couch_slave2
    environment:
        - NODENAME=172.20.0.5
    command: python /code/manage.py initcouchdb
    networks:
      backend:
        ipv4_address: 172.20.0.5
    deploy:
      mode: replicated
      replicas: 2
      placement:
        constraints: [node.role == worker]
        
networks:
  backend:
    driver: overlay
    ipam:
      config:
        - subnet: 172.20.0.0/16
